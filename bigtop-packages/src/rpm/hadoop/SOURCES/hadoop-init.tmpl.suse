#!/bin/bash
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Starts a Hadoop @HADOOP_DAEMON@
#
# chkconfig: 345 85 15
# description: Hadoop @HADOOP_DAEMON@
#
### BEGIN INIT INFO
# Provides:          hadoop-@HADOOP_DAEMON@
# Required-Start:    $syslog $remote_fs
# Should-Start:
# Required-Stop:     $syslog $remote_fs
# Should-Stop:
# Default-Start:     3 4 5
# Default-Stop:      0 1 2 6
# Short-Description: Hadoop @HADOOP_DAEMON@
### END INIT INFO

. /lib/lsb/init-functions
. /etc/default/hadoop

# Autodetect JAVA_HOME if not defined
if [ -e /usr/libexec/bigtop-detect-javahome ]; then
  . /usr/libexec/bigtop-detect-javahome
elif [ -e /usr/lib/bigtop-utils/bigtop-detect-javahome ]; then
  . /usr/lib/bigtop-utils/bigtop-detect-javahome
fi

RETVAL_SUCCESS=0

STATUS_RUNNING=0
STATUS_DEAD=1
STATUS_DEAD_AND_LOCK=2
STATUS_NOT_RUNNING=3
STATUS_OTHER_ERROR=102


ERROR_PROGRAM_NOT_INSTALLED=5
ERROR_PROGRAM_NOT_CONFIGURED=6


RETVAL=0
EXEC_PATH=@HADOOP_COMMON_ROOT@/sbin/hadoop-daemon.sh
CONFIG_PATH="@HADOOP_CONF_DIR@"
HADOOP_PID_DIR=${HADOOP_PID_DIR:-/var/run/hadoop}
PIDFILE="$HADOOP_PID_DIR/hadoop-$HADOOP_IDENT_STRING-@HADOOP_DAEMON@.pid"
LOCKFILE="/var/lock/subsys/hadoop-@HADOOP_DAEMON@"
desc="Hadoop @HADOOP_DAEMON@ daemon"
SLEEP_TIME=5

start() {
  [ -x $exec ] || exit $ERROR_PROGRAM_NOT_INSTALLED
  [ -f $config ] || exit $ERROR_PROGRAM_NOT_CONFIGURED
  log_success_msg "Starting $desc (hadoop-@HADOOP_DAEMON@): "

  TARGET_USER_NAME="HADOOP_`echo @HADOOP_DAEMON@ | tr a-z A-Z`_USER"
  TARGET_USER=$(eval "echo \$$TARGET_USER_NAME")

  if [ "@HADOOP_DAEMON@" = "datanode" ]; then
    # The following needs to be removed once HDFS-1943 gets finally put to rest.
    # The logic of this ugly hack is this: IFF we do NOT have jsvc installed it is
    # guaranteed that we can NOT be running in a secure mode and thus we need to
    # workaround HDFS-1943 (start as non-root). As soon as jsvc gets installed
    # we are assuming a secure installation and starting a data node as root.
    # This leaves 2 corner cases:
    #    1. HADOOP_DATANODE_USER being set to root
    #    2. jsvc is installed but Hadoop is configures to run in an unsecure mode
    # Both will currently fail
    if [ -f $HADOOP_HOME/libexec/jsvc.amd64 -o -f $HADOOP_HOME/libexec/jsvc.i386 ] && [ -n "$HADOOP_SECURE_DN_USER" ]; then
      TARGET_USER=root
    fi
  fi

  export HADOOP_IDENT_STRING=$TARGET_USER
  su -s /bin/bash $TARGET_USER -c "$EXEC_PATH --config '$CONFIG_PATH' start @HADOOP_DAEMON@ $DAEMON_FLAGS"

  # Some processes are slow to start
  sleep $SLEEP_TIME
  checkstatusofproc
  RETVAL=$?

  [ $RETVAL -eq $RETVAL_SUCCESS ] && touch $LOCKFILE
  return $RETVAL
}

stop() {
  log_success_msg "Stopping $desc (hadoop-@HADOOP_DAEMON@): "
  start_daemon $EXEC_PATH --config "$CONFIG_PATH" stop @HADOOP_DAEMON@
  RETVAL=$?

  [ $RETVAL -eq $RETVAL_SUCCESS ] && rm -f $LOCKFILE $PIDFILE

  if [ "@HADOOP_DAEMON@" = "datanode" ]; then
    # Some processes are slow to stop
    sleep $SLEEP_TIME
    checkstatusofproc
    RETVAL=$?

    # Stopping a non running process should be a success
    if [ $RETVAL -ne $STATUS_RUNNING ]; then
        RETVAL=0
    else
        RETVAL=$STATUS_OTHER_ERROR
    fi
  fi
}

restart() {
  stop
  start
}


checkstatusofproc(){
  # Under certain conditions datanode manifests as jsvc.exec
  if [ "@HADOOP_DAEMON@" = "datanode" -a -x @HADOOP_COMMON_ROOT@/sbin/Linux-amd64-64/jsvc ] ; then
    PROC_NAME="jsvc"
  else
    PROC_NAME="su"
  fi
  pidofproc -p $PIDFILE $PROC_NAME > /dev/null
}

checkstatus(){
  checkstatusofproc
  status=$?

  case "$status" in
    $STATUS_RUNNING)
      log_success_msg "@HADOOP_DAEMON@ is running"
      ;;
    $STATUS_DEAD)
      log_failure_msg "@HADOOP_DAEMON@ is dead and pid file exists"
      ;;
    $STATUS_DEAD_AND_LOCK)
      log_failure_msg "@HADOOP_DAEMON@ is dead and lock file exists"
      ;;
    $STATUS_NOT_RUNNING)
      log_failure_msg "@HADOOP_DAEMON@ is not running"
      ;;
    *)
      log_failure_msg "@HADOOP_DAEMON@ status is unknown"
      ;;
  esac
  return $status
}

condrestart(){
  [ -e $LOCKFILE ] && restart || :
}

check_for_root() {
  if [ $(id -ur) -ne 0 ]; then
    echo 'Error: root user required'
    echo
    exit 1
  fi
}

hadoopservice() {
  case "$1" in
    start)
      check_for_root
      start
      ;;
    stop)
      check_for_root
      stop
      ;;
    status)
      checkstatus
      RETVAL=$?
      ;;
    restart)
      check_for_root
      restart
      ;;
    condrestart|try-restart)
      check_for_root
      condrestart
      ;;
    *)
      if [ "@HADOOP_DAEMON@" = "namenode" ]; then
        if [ "$1" = "upgrade" -o "$1" = "rollback" ]; then
          DAEMON_FLAGS=-$1 $0 start
          RETVAL=$?
        else
          echo $"Usage: $0 {start|stop|status|restart|try-restart|condrestart|upgrade|rollback}"
          exit 1
        fi
      else
        echo $"Usage: $0 {start|stop|status|restart|try-restart|condrestart}"
        exit 1
      fi
  esac
}

hadoopservice "$1"

exit $RETVAL
