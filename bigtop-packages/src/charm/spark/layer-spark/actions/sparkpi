#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
sys.path.append('lib')

from path import Path
from time import time
import subprocess

from charmhelpers.contrib.benchmark import Benchmark
from charmhelpers.core import hookenv
from charms.reactive import is_state


def fail(msg, output):
    hookenv.action_set({'output': output})
    hookenv.action_fail(msg)
    sys.exit(1)


def main():
    bench = Benchmark()

    if not is_state('spark.started'):
        fail('Spark not yet ready', 'error')

    num_partitions = hookenv.action_get('partitions') or ''

    # create dir to store results
    run = int(time())
    result_dir = Path('/opt/sparkpi-results')
    result_log = result_dir / '{}.log'.format(run)
    if not result_dir.exists():
        result_dir.mkdir()
    result_dir.chown('ubuntu', 'ubuntu')

    bench.start()
    start = int(time())

    hookenv.log("values: {} {}".format(num_partitions, result_log))

    print('calculating pi')

    with open(result_log, 'w') as log_file:
        arg_list = [
            'spark-submit',
            '--class',
            'org.apache.spark.examples.SparkPi',
            '/usr/lib/spark/lib/spark-examples.jar'
        ]
        if num_partitions:
            # This is always blank. TODO: figure out what it was
            # supposed to do.
            arg_list.append(num_partitions)

        try:
            subprocess.check_call(arg_list, stdout=log_file,
                                  stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as e:
            print('smoke test command failed: ')
            print('{}'.format(' '.join(arg_list)))
            fail('spark-submit failed: {}'.format(e), 'error')

    stop = int(time())
    bench.finish()

    duration = stop - start
    bench.set_composite_score(duration, 'secs')
    subprocess.check_call(['benchmark-raw', result_log])

    with open(result_log) as log:
        success = False
        for line in log.readlines():
            if 'Pi is roughly 3.1' in line:
                success = True
                break

    if not success:
        fail('spark-submit did not calculate pi', 'error')

    hookenv.action_set({'output': {'status': 'completed'}})


if __name__ == '__main__':
    main()
