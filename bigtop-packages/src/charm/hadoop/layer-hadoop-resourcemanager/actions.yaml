smoke-test:
    description: Run an Apache Bigtop smoke test.
mrbench:
    description: Mapreduce benchmark for small jobs
    params:
        basedir:
            description: DFS working directory
            type: string
            default: "/benchmarks/MRBench"
        numruns:
            description: Number of times to run the job
            type: integer
            default: 1
        maps:
            description: number of maps for each run
            type: integer
            default: 2
        reduces:
            description: number of reduces for each run
            type: integer
            default: 1
        inputlines:
            description: number of input lines to generate
            type: integer
            default: 1
        inputtype:
            description: 'Type of input to generate, one of [ascending, descending, random]'
            type: string
            default: "ascending"
            enum: [ascending,descending,random]
nnbench:
    description: Load test the NameNode hardware and configuration
    params:
        maps:
                description: number of map jobs
                type: integer
                default: 12
        reduces:
                description: number of reduces
                type: integer
                default: 6
        blocksize:
                description: block size
                type: integer
                default: 1
        bytes:
                description: bytes to write
                type: integer
                default: 0
        numfiles:
                description: number of files
                type: integer
                default: 0
        repfactor:
                description: replication factor per file
                type: integer
                default: 3
        basedir:
                description: DFS working directory
                type: string
                default: "/benchmarks/NNBench"
testdfsio:
    description: DFS IO Testing
    params:
        mode:
                description: read or write IO test
                type: string
                default: "write"
                enum: [read,write]
        numfiles:
                description: number of files
                type: integer
                default: 10
        filesize:
                description: filesize in MB
                type: integer
                default: 1000
        buffersize:
                description: Buffer size in bytes
                type: string
                default: "1000000"
teragen:
    description: Generate data with teragen
    params:
        size:
            description: The number of 100 byte rows, default to 1GB of data to generate
            type: string
            default: "10000000"
        indir:
            description: HDFS directory where generated data is stored
            type: string
            default: '/benchmarks/TeraGen'
terasort:
    description: Runs teragen to generate sample data, and then runs terasort to sort that data
    params:
        indir:
            description: HDFS directory where generated data is stored
            type: string
            default: '/benchmarks/TeraGen'
        outdir:
            description: HDFS directory where sorted data is stored
            type: string
            default: '/benchmarks/TeraSort'
        size:
            description: The number of 100 byte rows, default to 1GB of data to generate and sort
            type: string
            default: "10000000"
        maps:
            description: The default number of map tasks per job. 1-20
            type: integer
            default: 1
        reduces:
            description: The default number of reduce tasks per job. Typically set to 99% of the cluster's reduce capacity, so that if a node fails the reduces can still be executed in a single wave. Try 1-20
            type: integer
            default: 1
        numtasks:
            description: How many tasks to run per jvm. If set to -1, there is no limit.
            type: integer
            default: 1
        compression:
            description: >
                        Enable or Disable mapred output (intermediate) compression.
                        LocalDefault will run with your current local hadoop configuration.
                        Default means default hadoop deflate codec.
                        One of: Gzip, BZip2, Snappy, Lzo, Default, Disable, LocalDefault
                        These are all case sensitive.
            type: string
            default: "LocalDefault"
            enum: [Gzip, BZip2, Snappy, Lzo, Default, Disable, LocalDefault]
